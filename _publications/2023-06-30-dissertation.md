---
title: "Evaluating, Explaining, and Utilizing Model Uncertainty in High-Performing, Opaque Machine Learning Models"
collection: publications
permalink: /publication/dissertation
excerpt: 'My dissertation on evaluating, explaining, and utilizing uncertainty in machine learning.'
date: 2023-06-30
venue: 'Dissertation'
paperurl: 'http://academicpages.github.io/files/paper1.pdf'
citation: 'Brown, KE. <i>Evaluating, Explaining, and Utilizing Model Uncertainty in High-Performing, Opaque Machine Learning Models</i> (Doctoral dissertation, Tennessee Technological University). 2023.'
---
Machine learning has made tremendous strides in the past decades at producing state-of-the-art results in safety-critical fields such as self-driving vehicles and medicine. Current advances in machine learning performance have come at the cost of model transparency. As the prevalence and predictive power of these models increase, so does the need for and investment in techniques to increase transparency in AI models. To improve trust in deep neural networks and tree-based ensembles, and by extension increase usage of these models, there has been an increased amount of research in eXplainable Artificial Intelligence (XAI) and Uncertainty Quantification (UQ). There is little work, however, in improving the interpretability of uncertainty quantification in high-performing, opaque models.

The overarching goal of this dissertation is to improve evaluation, explanation, utilization of uncertainty in machine learning in application-based scenarios. This is accomplished through four primary contributions. First, we present a probabilistic model to estimate joint human-AI partnership performance. Second, we present a novel technique to produce local explanations of uncertainty using the Regressionbased Uncertainty Function (RUF). Third, we present a novel technique to produce global explanations of uncertainty using the Quantifying Uncertainty for Estimating Subgroup Types (QUEST) system. Finally, we extend QUEST into a model assessment tool to identify error-prone or difficult to process subgroups of input data.

[Download paper here](http://academicpages.github.io/files/paper1.pdf)

Recommended citation: Brown, KE. <i>Evaluating, Explaining, and Utilizing Model Uncertainty in High-Performing, Opaque Machine Learning Models</i> (Doctoral dissertation, Tennessee Technological University). 2023.